{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Bioinformatics Analysis of Microbiome Data","text":""},{"location":"#1-introduction","title":"1. INTRODUCTION","text":"<p>We will be working with NGS data generated from 3 groups of mice: IL-10<sup>-/-</sup> (deficient), MUC2<sup>-/-</sup> (deficient), and wild-type mice.</p>"},{"location":"#11-data-type","title":"1.1 Data type:","text":"<p>The data was obtained through targeted amplification of the V4V5 region of the 16S rRNA gene and paired-end sequencing on the Illumina Miseq platform, resulting in forward and reverse reads of 250 bp length (each).</p> <p> Figure 1. Figure 1. Simplified illustration of the genetic region amplified and sequenced. A) The bacterial 16SrRNA gene is part of the ribosomal RNA operon. B) The 16S rRNA gene spans over 1,500 bp and contains conserved regions (light green) as well as variable regions (white). In this study, we targeted the variable regions V4 and V5 using the 515F forward primer and the 926R reverse primer. The targeted region has an approximate length of 411 bp, but library preparation results in longer reads as barcodes are also added.  </p>"},{"location":"about/","title":"About","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"commands/","title":"Useful Terminal/PowerShell Commands","text":"<p>Depending on your operating system, open either terminal (Mac) or PowerShell (Windows). There are some similarities and some differences between Terminal and PowerShell commands. One important one is the usage of slashes (/) in case of Mac, and backslashes () in case of Windows, when specifying a path. </p>"},{"location":"commands/#1-list-files-in-the-current-working-directory","title":"1. List files in the current working directory","text":"<pre><code>ls\n</code></pre>"},{"location":"commands/#2-change-directory","title":"2. Change directory","text":""},{"location":"commands/#21-relative-path","title":"2.1 Relative path","text":"<p><pre><code>cd ./Downloads\n</code></pre> the . before slash (/) means current directory <pre><code>cd ..\n</code></pre> .. means parent directory</p>"},{"location":"commands/#22-absolute-path","title":"2.2 Absolute path","text":"MacWindows <pre><code>cd Users/Peter/Downloads\n</code></pre> <pre><code>cd C:\\Users\\Peter\\Downloads\n</code></pre>"},{"location":"commands/#3-create-directory","title":"3. Create directory","text":"<p><pre><code>mkdir example\n</code></pre> <pre><code>ls\n</code></pre> You should now see a directory called \"example\" in your current working directory. </p>"},{"location":"commands/#4-create-a-txt-file","title":"4. Create a .txt file","text":"MacWindows <pre><code>cat &gt; test.txt\n</code></pre> <pre><code>New-Item test.txt\n</code></pre> <p>Write something in the file (at least two lines). </p>"},{"location":"commands/#5-head-and-tail","title":"5. Head and Tail","text":"<p>When working with large files, we encourage you examine them. Since files are often too big to be loaded into Excel, head and tail commands are good alternatives to get a good idea of what the file looks like (this only works for unzipped files, i.e. non-binary).</p> MacWindows <pre><code>head -10 test.txt\n</code></pre> <pre><code>Get-Content test.txt -Head 10\n</code></pre> <p>You can replace the word head with tail to see the end of the file. </p>"},{"location":"commands/#6-docker","title":"6. Docker","text":"<p>Docker is a tool designed to make it easier to create, deploy, and run applications by using containers. Containers allow a developer to package up an application with all of the parts it needs, such as operating system, libraries and other dependencies, and ship it all out as one package.</p> <p>By running the following command, you create a docker container from an image that includes Ubuntu distribution and QIIME2.</p> <pre><code>docker run --rm -v ${pwd}:/data/ -w /data/ -it quay.io/qiime2/amplicon:2025.7\n</code></pre> <p>After running this command, you should be in the container. This is indicated by the following text in your terminal (qiime2-2023.5). Once you list the files in the current working directory the files on your local computer should be reflected in the printed list. </p> <p>We encourage you to check the help command and identify what each of the options mean (e.g. --rm, -it, -v, -w).</p> <p><pre><code>$ docker run --help\n</code></pre> Files that you create while running qiime2 in the docker container will be reflected in your local directory after running the workflow commands. </p>"},{"location":"installation_instructions/","title":"Installation Instructions","text":"<p>All students must bring their own laptop and install the required software before the start of the practicals.</p> <p>We will provide a troubleshooting session on Tuesday (16.9.2025) after the lecture for those who encounter installation issues.</p>"},{"location":"installation_instructions/#required-software","title":"Required Software","text":"<ol> <li>Docker (Only Windows users)</li> <li>QIIME2</li> <li>FastQC</li> <li>R + RStudio</li> </ol> <p>If you have questions, please email us at bioinformatics.bme307@gmail.com.</p>"},{"location":"installation_instructions/#windows-users-recommended-docker-based-qiime2","title":"\ud83d\udcbb Windows Users (recommended: Docker-based QIIME2)","text":""},{"location":"installation_instructions/#1-docker-qiime2","title":"1. Docker + QIIME2","text":"<p>Check if Virtualization is enabled</p> <ul> <li>Press Ctrl + Alt + Del \u2192 Task Manager \u2192 Performance \u2192 CPU</li> <li>Check if Virtualization: Enabled</li> <li>If not, follow these BIOS instructions (steps differ by brand: Acer, Asus, Dell, HP, Lenovo, Sony, Toshiba).</li> </ul> <ol> <li> <p>Install Docker Desktop for Windows: Download here</p> </li> <li> <p>Run the <code>.exe</code> file and select Enable WSL 2 Features when prompted.</p> </li> <li> <p>If you see:    \u201cDocker Desktop requires Windows \u2026\u201d</p> </li> <li> <p>Update Windows here and reinstall Docker.</p> </li> <li> <p>If you encounter WSL2 errors, install the Linux kernel update package.</p> </li> <li> <p>Start Docker Desktop.</p> </li> <li> <p>The whale \ud83d\udc33 icon in the status bar should stay steady.</p> </li> <li> <p>Test Docker with:</p> </li> </ol> <pre><code>docker run hello-world\n</code></pre> <ol> <li>Download QIIME2:</li> </ol> <pre><code>docker pull quay.io/qiime2/amplicon:2025.7\n</code></pre> <ol> <li>Test QIIME2:</li> </ol> <pre><code>docker run -v ${PWD}:/data -it quay.io/qiime2/amplicon:2025.7 qiime info\n</code></pre>"},{"location":"installation_instructions/#2-fastqc","title":"2. FastQC","text":"<ol> <li>Download FastQC for Windows: FastQC v0.12.1.</li> <li>Extract the <code>.zip</code> file.</li> <li> <p>Run <code>fastqc.exe</code>.</p> </li> <li> <p>If Java errors occur, install Java JDK 21.</p> </li> </ol>"},{"location":"installation_instructions/#3-r-rstudio","title":"3. R + RStudio","text":"<ol> <li>Install R for Windows.</li> <li>Install RStudio for Windows.</li> <li>Open RStudio to confirm installation works.</li> </ol>"},{"location":"installation_instructions/#mac-users-intel-apple-silicon-m1m4","title":"\ud83c\udf4e Mac Users (Intel &amp; Apple Silicon M1\u2013M4)","text":""},{"location":"installation_instructions/#1-install-conda","title":"1. Install Conda","text":"<ul> <li>Recommended: Miniconda</li> <li>Open Terminal and verify:</li> </ul> <pre><code>conda --version\n</code></pre>"},{"location":"installation_instructions/#2-qiime2","title":"2. QIIME2","text":""},{"location":"installation_instructions/#intel-macs-x86_64","title":"Intel Macs (x86_64)","text":"<pre><code>conda update conda\nconda env create --name qiime2-amplicon-2025.7 \\\n  --file https://raw.githubusercontent.com/qiime2/distributions/refs/heads/dev/2025.7/amplicon/released/qiime2-amplicon-macos-latest-conda.yml\nconda activate qiime2-amplicon-2025.7\n</code></pre>"},{"location":"installation_instructions/#apple-silicon-macs-m1m4-arm64","title":"Apple Silicon Macs (M1\u2013M4, arm64)","text":"<p>Use the <code>osx-64</code> builds via Rosetta:</p> <pre><code>CONDA_SUBDIR=osx-64 conda env create \\\n  --name qiime2-amplicon-2025.7 \\\n  --file https://raw.githubusercontent.com/qiime2/distributions/refs/heads/dev/2025.7/amplicon/released/qiime2-amplicon-macos-latest-conda.yml\n\nconda activate qiime2-amplicon-2025.7\nconda config --env --set subdir osx-64\n</code></pre>"},{"location":"installation_instructions/#test-installation","title":"Test installation","text":"<pre><code>qiime info\n</code></pre> <p>If successful, this will print information about the QIIME2 version.</p>"},{"location":"installation_instructions/#3-fastqc","title":"3. FastQC","text":"<ol> <li>Download the <code>.dmg</code>: FastQC v0.12.1.</li> <li>If macOS blocks the app, install Java JDK 21 for Mac.</li> </ol> <p>If FastQC still doesn\u2019t launch:</p> <ul> <li>Download the source code.</li> <li>Unzip \u2192 open Terminal \u2192 navigate to the unzipped folder \u2192 run:</li> </ul> <pre><code>./fastqc\n</code></pre>"},{"location":"installation_instructions/#make-fastqc-executable-from-anywhere","title":"\ud83d\udd17 Make FastQC executable from anywhere","text":"<p>After unzipping, create a symbolic link so <code>fastqc</code> works globally.</p> <p>Intel Macs (x86_64):</p> <pre><code>sudo ln -s ~/Downloads/FastQC/fastqc /usr/local/bin/fastqc\nsudo chmod +x /usr/local/bin/fastqc\n</code></pre> <p>Apple Silicon Macs (M1\u2013M4, arm64):</p> <pre><code>sudo ln -s ~/Downloads/FastQC/fastqc /opt/homebrew/bin/fastqc\nsudo chmod +x /opt/homebrew/bin/fastqc\n</code></pre> <p>(adjust the path if your FastQC folder is elsewhere)</p>"},{"location":"installation_instructions/#test-the-installation","title":"Test the installation","text":"<p>Run:</p> <pre><code>fastqc -h\n</code></pre> <p>If installed correctly, this will print the FastQC help menu.</p>"},{"location":"installation_instructions/#4-r-rstudio","title":"4. R + RStudio","text":"<ol> <li>Install R for macOS.</li> <li>Install RStudio for macOS.</li> <li>Open RStudio to confirm installation.</li> </ol>"},{"location":"installation_instructions/#linux-users","title":"\ud83d\udc27 Linux Users","text":""},{"location":"installation_instructions/#1-docker-recommended-for-simplicity","title":"1. Docker (recommended for simplicity)","text":"<p>Install Docker:</p> <pre><code>sudo apt-get update\nsudo apt-get install docker.io\n</code></pre> <p>Test Docker:</p> <pre><code>docker run hello-world\n</code></pre> <p>Download and test QIIME2:</p> <pre><code>docker pull quay.io/qiime2/amplicon:2025.7\ndocker run -v ${PWD}:/data -it quay.io/qiime2/amplicon:2025.7 qiime info\n</code></pre>"},{"location":"installation_instructions/#2-fastqc_1","title":"2. FastQC","text":"<pre><code>sudo apt-get install fastqc\n</code></pre> <p>Or download from FastQC site.</p>"},{"location":"installation_instructions/#3-r-rstudio_1","title":"3. R + RStudio","text":"<pre><code>sudo apt-get install r-base\n</code></pre> <p>Download RStudio: Linux RStudio.</p>"},{"location":"qiime2_pipeline/","title":"QIIME2 primer","text":""},{"location":"qiime2_pipeline/#what-is-qiime2","title":"What is QIIME2?","text":"<p>As described on the QIIME2 portal :</p> What is QIIME 2? <p>QIIME 2 is a powerful, extensible, and decentralized microbiome analysis package with a focus on data and analysis transparency. QIIME 2 enables researchers to start an analysis with raw DNA sequence data and finish with publication-quality figures and statistical results.  </p>"},{"location":"qiime2_pipeline/#qiime2-overview","title":"QIIME2 Overview","text":"<p>From https://docs.qiime2.org/2023.7/tutorials/overview/: </p>"},{"location":"qiime2_pipeline/#qiime2-artifacts","title":"QIIME2 Artifacts","text":"<p>In QIIME2, we use \u201cartifacts\u201d instead of data files (e.g. FASTA files): these contain not only data but also additional information on the generation of the file itself. Therefore, before we start working with QIIME2, we need to import our data as a QIIME2 artifact. </p> <p>Additional info: As described on the QIIME2 website (https://docs.qiime2.org/2023.7/concepts/): </p> <p>\u201cArtifacts enable QIIME 2 to track, in addition to the data itself, the provenance of how the data came to be. With an artifact\u2019s provenance, you can trace back to all previous analyses that were run to produce the artifact, including the input data used at each step. This automatic, integrated, and decentralized provenance tracking of data enables a researcher to archive artifacts, or for example, send an artifact to a collaborator, with the ability to understand exactly how the artifact was created. This enables replicability and reproducibility of analyses, as well as generation of diagrams and text that can be used in the methods section of a paper. Provenance also supports and encourages the proper attribution to underlying tools (e.g. FastTree to build a phylogenetic tree) used to generate the artifact.\u201d</p> <p>Before we get started, let's briefly discuss the two main file types used with QIIME2. These are <code>.qza</code> files and <code>.qzv</code> files.</p> <p><code>.qza</code> - The QIIME2 artifact file. These contain data.</p> <p><code>.qzv</code> - The QIIME2 visualization file. These contain visualizations that can be viewed using QIIME 2 View.</p> <p>In this course, we will mostly be using Qiime2view to visualise (instead of unzipping the qza file). You simply need to drag and drop the file of interest. </p>"},{"location":"r_studio/","title":"R studio","text":"<p>We will be using the R package Phyloseq to examine the microbiome data. As specified on their website, Phyloseq is a tool to \u201cimport, store, analyze, and graphically display complex phylogenetic sequencing data\u201d. </p> <p>Set your working directories, install the necessary packages, and load the libraries. In case you are not familiar with R packages, a detailed beginner\u2019s guide is available here</p>"},{"location":"r_studio/#on-thursday","title":"On Thursday","text":""},{"location":"r_studio/#1-package-installation-and-library-loading","title":"1. Package Installation and Library Loading","text":""},{"location":"r_studio/#install-biocmanager","title":"Install BiocManager","text":"<pre><code>install.packages(\"BiocManager\")\n</code></pre>"},{"location":"r_studio/#install-bioconductor-packages","title":"Install Bioconductor packages","text":"<pre><code>BiocManager::install(c(\"phyloseq\", \"Biostrings\", \"S4Vectors\", \"IRanges\", \"XVector\"))\n</code></pre>"},{"location":"r_studio/#install-cran-packages","title":"Install CRAN packages","text":"<pre><code>install.packages(c(\"vegan\", \"ape\", \"data.table\", \"Rcpp\", \"forcats\", \"tidyverse\"))\n</code></pre> <p>Quick check:</p> <pre><code>library(phyloseq)\npackageVersion(\"phyloseq\")\n</code></pre>"},{"location":"r_studio/#install-qiime2r","title":"Install qiime2R","text":"<pre><code>install.packages(\"remotes\")\nremotes::install_url(\n  \"https://github.com/jbisanz/qiime2R/archive/refs/heads/master.zip\",\n  dependencies = TRUE\n)\n</code></pre>"},{"location":"r_studio/#install-phyloseq-extended","title":"Install phyloseq-extended","text":"<pre><code>install.packages(\"remotes\")   # only needed once, can skip if already installed\nlibrary(remotes)\nremotes::install_github(\"mahendra-mariadassou/phyloseq-extended\", ref = \"dev\")\n</code></pre>"},{"location":"r_studio/#alternative-installation-only-if-install_github-fails-with-http-error-401","title":"Alternative installation (only if <code>install_github()</code> fails with HTTP error 401)","text":"<pre><code># install.packages(\"gitcreds\")   # if not already installed\n# library(gitcreds)\n# gitcreds::gitcreds_get()       # check credentials\n# gitcreds::gitcreds_delete()    # delete stored GitHub token if invalid\n# remotes::install_github(\"mahendra-mariadassou/phyloseq-extended\", ref = \"dev\")\n</code></pre> <p>Quick check:</p> <pre><code>library(phyloseq.extended)\npackageVersion(\"phyloseq.extended\")\n</code></pre>"},{"location":"r_studio/#load-libraries","title":"Load libraries","text":"<pre><code>library(qiime2R)\nlibrary(tidyverse)\nlibrary(vegan)\nlibrary(ape)\nlibrary(Rcpp)\nlibrary(data.table)\nlibrary(phyloseq.extended)\n</code></pre>"},{"location":"r_studio/#version-check","title":"Version check","text":"<pre><code>pkgs &lt;- c(\"phyloseq\", \"qiime2R\", \"microbiome\", \"vegan\", \"ape\", \"tidyverse\")\nsapply(pkgs, \\(p) as.character(packageVersion(p)))\n</code></pre>"},{"location":"r_studio/#2-import-qiime2-files-to-phyloseq","title":"2. Import QIIME2 files to phyloseq","text":"<p>After importing the necessary files, you can build a phyloseq object for manipulation with phyloseq functions. Once you have built it, enter the name of the object (pseq) to see what it looks like.</p> <pre><code># Define path to QIIME2 files\nfiles_path &lt;- \"/Path/to/Practical_materials_uploads/QIIME2_files\"\n\n# (Optional) Read tree file to check contents\nread_qza(file.path(files_path, \"rooted-tree.qza\"))\n\n# Convert QIIME2 artefacts to a phyloseq object\npseq &lt;- qza_to_phyloseq(\n  features  = file.path(files_path, \"table.qza\"),\n  taxonomy  = file.path(files_path, \"taxonomy.qza\"),\n  metadata  = file.path(files_path, \"metadata.tsv\"),\n  tree      = file.path(files_path, \"rooted-tree.qza\")\n)\n\n# Display phyloseq object\npseq\n</code></pre> Expected Output <pre><code>phyloseq-class experiment-level object \notu_table()   OTU Table:         [ 502 taxa and 18 samples ] \nsample_data() Sample Data:       [ 18 samples by 2 sample variables ]\ntax_table()   Taxonomy Table:    [ 502 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 502 tips and 500 internal nodes ]\n</code></pre> <pre><code># Save and reload phyloseq object\nsave(pseq, file = \"pseq.RData\")\nload(\"pseq.RData\")\n</code></pre>"},{"location":"r_studio/#3-explore-the-phyloseq-object","title":"3. Explore the <code>phyloseq</code> Object","text":"<p>In this section we explore different phyloseq accessors to get familiar with the contents of our object. In case you want to get more info, you can enter \u201c?phyloseq\u201d to find out more.</p>"},{"location":"r_studio/#inspect-the-three-core-tables","title":"Inspect the three core tables","text":"<pre><code>head(otu_table(pseq))     # abundance matrix\nhead(tax_table(pseq))     # taxonomy\nhead(sample_data(pseq))   # metadata\n</code></pre>"},{"location":"r_studio/#basic-information","title":"Basic information","text":"<pre><code>ntaxa(pseq)               # number of taxa\nnsamples(pseq)            # number of samples\nsample_names(pseq)        # sample IDs\nhead(taxa_names(pseq))    # taxon (ASV) IDs\n</code></pre>"},{"location":"r_studio/#relabel-the-asvs-with-numbers","title":"Relabel the ASVs with numbers","text":"<pre><code>original_ids &lt;- taxa_names(pseq)\nasv_labels &lt;- paste0(\"ASV\", seq_len(ntaxa(pseq)))\ntaxa_names(pseq) &lt;- asv_labels\ntax_table(pseq) &lt;- cbind(tax_table(pseq), OriginalID = original_ids)\n\nhead(taxa_names(pseq))\n</code></pre>"},{"location":"r_studio/#more-accessors","title":"More accessors","text":"<pre><code>sample_sums(pseq)                     # total reads per sample\nhead(taxa_sums(pseq))                 # total reads per taxon\nsample_sums(pseq)[sample_names(pseq)==\"IL10-2\"]  # depth of one sample\nrank_names(pseq)                      # available taxonomic ranks\nsample_variables(pseq)                # metadata variables\nget_variable(pseq, \"type\")            # values of a metadata variable\n</code></pre>"},{"location":"r_studio/#extract-sample-specific-information","title":"Extract sample-specific information","text":"<pre><code># Counts for one sample (if taxa are rows, samples are columns)\notu_table(pseq)[, \"WT4\"]\n\n# Metadata for one sample\nsample_data(pseq)[\"WT4\", ]\n\n# Prune the object to only WT4\nprune_samples(\"WT4\", pseq)\n</code></pre>"},{"location":"r_studio/#taxonomy-queries","title":"Taxonomy queries","text":"<pre><code>get_taxa_unique(pseq, \"Phylum\")\nget_taxa_unique(pseq, \"Family\")\nget_taxa_unique(pseq, \"Class\")\nget_taxa_unique(pseq, \"Genus\")\n</code></pre> Question(s) <ol> <li>How many samples are there?</li> <li>How many ASVs are there in total?</li> <li>When you look at sample_sums, what sample has the highest number of reads, and what sample has the lowest number?</li> <li>Explore the number of unique phyla, orders, families, and genera: how many taxa are there in each taxonomic rank? Do you observe any unclassified taxa?</li> </ol>"},{"location":"r_studio/#4-read-depth","title":"4. Read depth","text":"<p>Let\u2019s investigate the read depths for each sample. We will plot the read depth for each sample and visualise. To do so you need to make a dataframe called pseq_sum containing the relevant information (sample ID, read depth and type). </p>"},{"location":"r_studio/#show-distribution-of-read-counts","title":"Show distribution of read counts","text":"<pre><code># total reads per sample\nss &lt;- sample_sums(pseq)\n\nhist(\n  ss,\n  breaks = 30,\n  xaxt = \"n\",\n  main = \"Distribution of total reads per sample\",\n  xlab = \"Reads per sample\"\n)\naxis(1, at = pretty(ss))\n</code></pre> <pre><code># Convert sample_data to a plain data.frame\nmeta &lt;- as.data.frame(sample_data(pseq))\n\n# Assuming your metadata has a column named 'type'\npseq_sum &lt;- data.frame(\n  sampleID    = sample_names(pseq),\n  read_depth  = ss,\n  type        = meta$type,\n  row.names   = sample_names(pseq),\n  check.names = FALSE\n)\n\n# Peek at the first few rows\nhead(pseq_sum)\n</code></pre> <pre><code># Order samples by depth for a clearer plot\npseq_sum$sampleID &lt;- factor(\n  pseq_sum$sampleID,\n  levels = pseq_sum$sampleID[order(pseq_sum$read_depth, decreasing = TRUE)]\n)\n\nread_depth_sum &lt;- ggplot(pseq_sum, aes(x = sampleID, y = read_depth, fill = type)) +\n  geom_col() +\n  labs(\n    title = \"Total number of reads\",\n    x = \"Samples (ordered by depth)\",\n    y = \"Number of reads\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)\n  )\n\nread_depth_sum\n</code></pre> Question(s) <ol> <li>Is there a difference in read depth across the different groups of mice (WT, IL10, MUC2)?</li> </ol>"},{"location":"r_studio/#5-rarefaction-curve-and-alpha-diversity","title":"5. Rarefaction curve and alpha diversity","text":"<p>Use ?rarecurve to find out how to generate a simple rarefaction curve. You can also use ggrare to make a visually more appealing rarefaction curve. In the rarefaction curve, check how the observed number of ASVs changes with read depth, to find out if the samples are comparable.</p>"},{"location":"r_studio/#rarefaction-curves-with-vegan","title":"Rarefaction curves with <code>vegan</code>","text":"<pre><code>library(phyloseq)\nlibrary(vegan)\n\n# 1) Get counts as a plain matrix with SAMPLES IN ROWS (what vegan expects)\nmat &lt;- as(otu_table(pseq), \"matrix\")\nif (taxa_are_rows(pseq)) mat &lt;- t(mat)\n\n# Optional: drop all-zero samples (rare but safer)\nmat &lt;- mat[rowSums(mat) &gt; 0, , drop = FALSE]\n</code></pre> <pre><code># 2) Quick rarefaction curves\nhist(rowSums(mat), main = \"Library sizes\", xlab = \"Reads per sample\")\n\nraremax &lt;- min(rowSums(mat))\n\nrarecurve(\n  mat,\n  step = 1000,\n  label = TRUE,\n  cex = 0.5\n)\n</code></pre> <pre><code># 3) use phyloseq.extended to plot the rarefaction curves\nlibrary(phyloseq.extended)\n\nphyloseq.extended::ggrare(\n  pseq,\n  step = 1000,\n  color = \"type\",\n  se = TRUE\n)\n</code></pre> Question(s) <ol> <li>Are the read depths in the samples adequate? </li> <li>Are they representative of the true diversity in the mice?</li> </ol> <p>Next, let\u2019s look at several alpha diversity values. Generate the plots for \u201cObserved_richness\u201d, which is based on the number of different ASVs, and \u201cShannon\u201d, which takes into account evenness in addition to ASVs.</p> <pre><code># 4) Plot Observed Richness\n\nObsR_plot &lt;- plot_richness(\n  pseq,\n  x = \"type\",\n  color = \"type\",\n  measures = c(\"Observed\", \"Shannon\")\n) + \n  geom_boxplot()\n\nObsR_plot   # just print it\n</code></pre> Question(s) <ol> <li>Do you observe differences between the mouse groups (WT, MUC2, IL-10) based on these plots?</li> </ol>"},{"location":"r_studio/#6-normalize-the-data","title":"6. Normalize the data","text":"<p>As you have observed, read depth differs across samples. To compare bacterial community composition across the samples, we normalise the data: we compute the relative abundance for each ASV in each sample (ASV read counts/total reads in each sample). Now we have proportions that we can compare. </p>"},{"location":"r_studio/#normalize-read-counts-to-relative-abundance-so-samples-are-comparable","title":"Normalize read counts to relative abundance so samples are comparable.","text":"<pre><code>library(phyloseq)\n\n# Normalize to proportions within each sample\npseq_normal &lt;- transform_sample_counts(pseq, function(x) x / sum(x))\n\n# Inspect the normalized object\nhead(otu_table(pseq_normal))\n\n# Sanity check: each sample should sum to ~1\nsummary(sample_sums(pseq_normal))\n</code></pre>"},{"location":"r_studio/#7-taxonomic-composition","title":"7. Taxonomic composition","text":"<p>We will generate plots to visualise the bacterial community composition of the samples. Notice the y-axis which is relative abundance. You can choose which taxonomic rank (eg class, order, family, genus, species) and also whether you want to select a subset eg the 10 most abundant. </p>"},{"location":"r_studio/#check-unassignedmissing-taxonomy","title":"Check unassigned/missing taxonomy","text":"<pre><code>library(phyloseq)\nlibrary(dplyr)\n\nstopifnot(!is.null(tax_table(pseq_normal)))  # ensure taxonomy is present\n\ncheck_taxonomy_quality &lt;- function(ps) {\n  tt &lt;- as(tax_table(ps), \"matrix\")\n  # ensure character\n  tt &lt;- apply(tt, 2, function(x) as.character(x))\n  # label vector to detect common \u201cunknowns\u201d\n  is_unassigned &lt;- function(x) {\n    y &lt;- tolower(trimws(x))\n    y %in% c(\"unassigned\", \"unknown\", \"uncultured\", \"incertae sedis\", \"incertae_sedis\")\n  }\n  out &lt;- apply(tt, 2, function(col) {\n    n_total &lt;- length(col)\n    n_na    &lt;- sum(is.na(col))\n    n_blank &lt;- sum(trimws(col) == \"\", na.rm = TRUE)\n    n_unas  &lt;- sum(is_unassigned(col), na.rm = TRUE)\n    c(Total = n_total, Missing = n_na, Blank = n_blank, Unassigned = n_unas)\n  })\n  as.data.frame(t(out))\n}\n\ncheck_taxonomy_quality(pseq_normal)\n</code></pre> <pre><code>library(phyloseq)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n# Parameters\nrank  &lt;- \"Genus\"   # e.g., \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"\ntopN  &lt;- 15        # keep top-N taxa globally; rest collapsed into \"Other\"\n</code></pre> <pre><code># 1) Agglomerate to chosen rank\nstopifnot(rank %in% rank_names(pseq_normal))\nps_glom &lt;- tax_glom(pseq_normal, taxrank = rank, NArm = TRUE)\n</code></pre> <pre><code># 2) Melt to tidy long format\ndf &lt;- psmelt(ps_glom) %&gt;%\n  mutate(\n    Taxon = dplyr::coalesce(!!sym(rank), \"Unassigned\")\n  )\n</code></pre> <pre><code># 3) Identify global top-N taxa by mean relative abundance\ntop_taxa &lt;- df %&gt;%\n  group_by(Taxon) %&gt;%\n  summarise(mean_abund = mean(Abundance), .groups = \"drop\") %&gt;%\n  arrange(desc(mean_abund)) %&gt;%\n  slice_head(n = topN) %&gt;%\n  pull(Taxon)\n</code></pre> <pre><code># 4) Collapse others to \"Other\" and re-sum within sample\ndf_bar &lt;- df %&gt;%\n  mutate(Taxon_collapsed = ifelse(Taxon %in% top_taxa, Taxon, \"Other\")) %&gt;%\n  group_by(Sample, Taxon_collapsed) %&gt;%\n  summarise(Abundance = sum(Abundance), .groups = \"drop\") %&gt;%\n  left_join(\n    as(sample_data(ps_glom), \"data.frame\") %&gt;% tibble::rownames_to_column(\"Sample\"),\n    by = \"Sample\"\n  )\n</code></pre> <pre><code># 5) Plot\nTopTaxa &lt;- ggplot(df_bar, aes(x = Sample, y = Abundance, fill = Taxon_collapsed)) +\n  geom_col() +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"Sample\",\n    y = \"Relative abundance\",\n    fill = rank,\n    title = paste0(\"Taxonomic composition (\", rank, \", top \", topN, \")\")\n  ) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\nTopTaxa  + scale_fill_manual(values=colorRampPalette(brewer.pal(12,\"Paired\"))(16))\n</code></pre> Question(s) <ol> <li>Visualise the taxa at the level of the different taxonomic ranks (eg phylum, class, order, family, genus). You will need to go back and check the number of taxa at each rank. What patterns do you observe for the different mouse groups at each of the taxonomic ranks?</li> <li>Now subset to visualise the top 10 most abundant taxa, choosing several taxonomic ranks. What patterns do you observe? Bonus: what happens if you select another number instead of 10?</li> </ol>"},{"location":"r_studio/#on-friday","title":"On Friday","text":"<p>With beta diversity analyses we focus on the similarities and differences among samples. To visually explore the data, we use principal coordinates analyses (PCoA) plots, utilizing different distance metrics such as weighted Unifrac and Bray Curtis.</p>"},{"location":"r_studio/#1-set-working-directory","title":"1. Set working directory","text":"<pre><code># Tip: prefer relative paths (here::here()) in shared scripts. Keeping your path for Friday:\nsetwd(\"/Users/peterresutik/Documents/Postdoc/Teaching/2025_Fall/Practical_materials_uploads/QIIME2_files_2025_August_18\")\n\n# Clean workspace (do this before loading objects)\nrm(list = ls())\n\n# Quick checks\ngetwd()\nlist.files()\n</code></pre>"},{"location":"r_studio/#2-load-data","title":"2. Load data","text":"<pre><code># Load the phyloseq object created earlier\nload(\"pseq.RData\")  # loads 'pseq'\n</code></pre>"},{"location":"r_studio/#3-normalization","title":"3. Normalization","text":"<pre><code># Relative abundance normalization (compositional)\nkeep &lt;- sample_sums(pseq) &gt; 0\npseq &lt;- prune_samples(keep, pseq)\n\npseq_normal &lt;- transform_sample_counts(pseq, function(x) x / sum(x))\n\n# Quick sanity checks\nhead(otu_table(pseq_normal))\nsummary(sample_sums(pseq_normal))  # ~1 for all samples\n\n# (Optional) Rarefy to an even depth for UniFrac comparability\n# min_depth &lt;- min(sample_sums(pseq))\n# set.seed(1)\n# pseq_rare &lt;- rarefy_even_depth(pseq, sample.size = min_depth, rngseed = 1,\n#                                replace = FALSE, verbose = FALSE)\n</code></pre>"},{"location":"r_studio/#4-beta-diversity-pcoa","title":"4. Beta diversity - PCoA","text":"<pre><code># Show available distance methods\nunlist(distanceMethodList)\n\n# --- A) Weighted UniFrac ---\nDist_wUF &lt;- distance(pseq_normal, method = \"wunifrac\")  # exact spelling!\nord_wUF  &lt;- ordinate(pseq_normal, method = \"PCoA\", distance = Dist_wUF)\n\nplot_scree(ord_wUF, \"Scree Plot: weighted UniFrac\")\n\nPoC_wUni &lt;- plot_ordination(pseq_normal, ord_wUF, color = \"type\", label = \"SampleID\") +\nggtitle(\"Weighted UniFrac\") +\ntheme_bw()\nPoC_wUni\n\n\n# --- B) Bray-Curtis ---\nDist_Bray &lt;- distance(pseq_normal, method = \"bray\")\nord_Bray  &lt;- ordinate(pseq_normal, method = \"PCoA\", distance = Dist_Bray)\n\nplot_scree(ord_Bray, \"Scree Plot: Bray-Curtis\")\n\nPoC_Bray &lt;- plot_ordination(pseq_normal, ord_Bray, color = \"type\", label = \"SampleID\") +\n  ggtitle(\"Bray-Curtis\") +\n  theme_bw()\nPoC_Bray\n</code></pre>"},{"location":"r_studio/#5-significance-tests","title":"5. Significance tests","text":"<pre><code>#Test significance with permanova analyses\n#First we generate a dataframe with the metadata\nsampledf&lt;- data.frame(sample_data(pseq_normal))\nsampledf\n\n#Next we calculate significance for unweighted Unifrac\npseq_p_wUF &lt;- adonis2(Dist_wUF ~type, data = sampledf)\npseq_p_wUF\n\n#We can also test for differences in dispersion \n#for unweighted unifrac\nbetawUF &lt;- betadisper(Dist_wUF, sampledf$type)\npermutest(betawUF)\n</code></pre> Question(s) <ol> <li>Do you observe differences across the mouse groups? Are there outliers in your plot? If so, what could explain these outliers?</li> <li>Can the clustering patterns be explained by the mouse type (eg WT, IL10 and MUC2)? Run the permanova tests (with adonis) to find out.</li> <li>Are there differences in dispersion among the groups? Run the dispersion tests (with betadisper) to find out.</li> </ol>"},{"location":"workflow/","title":"Workflow","text":""},{"location":"workflow/#preliminary-read-processing","title":"PRELIMINARY READ PROCESSING","text":"<p>In our pipeline we will be working with reads that have already been demultiplexed. You will need to download the following starting folder for your analyses: Practical_materials_uploads. The folder is structured as follows.</p>"},{"location":"workflow/#folder-structure","title":"Folder Structure","text":"<p>For each sample, there are two fastq files (R1 and R2). R1 corresponds to all the forward reads and R2 to all the reverse reads.</p> <p>We will first look at the fastq files, then check the quality of the reads with FastQC and MultiQC, and then conduct read processing in QIIME2 (denoising and OTU clustering). Follow the steps below:</p>"},{"location":"workflow/#1-check-the-fastq-files","title":"1.  Check the fastq files","text":"<p>After sequencing, the output is provided in the form of two FASTQ files per sample, one labelled R1 (forward reads) and one labelled R2 (reverse reads). Each FASTQ file contains reads, and these are provided as an entry with 4 lines: </p> <ol> <li>The first line contains a sequence identifier, including information about the sequencing run and the cluster. It usually begins with an \u201c@\u201d.</li> <li>The second line contains the base calls of the sequence (A, C, T, G and N).</li> <li>The third line comprises a plus (+) sign, which acts as a separator.</li> <li>The fourth line, which is important for the next step, provides information on the quality of each of the base calls. These are Phred +33 encoded, using ASCII characters to represent the numerical quality scores.</li> </ol> <p>An example of one entry of a FASTQ file (note that this corresponds to only one read of hundreds or thousands sequenced): </p> Exercise 1 <p>Select two fastq files, one corresponding to forward reads (R1) and one corresponding to reverse reads (R2). Copy them to a new folder called Raw_data_unzipped. Unzip them either with double clicking (on a Windows machine) or by running the following command gzip -d NAME_OF_THE_FILE (on a Mac). Next, explore the files using the command line (tip: use the commands you learnt previously).</p> Question(s): <ol> <li>Is the file format as expected?</li> <li>How many reads (entries) are there in each of these two files?</li> </ol>"},{"location":"workflow/#2-quality-check-using-fastqc","title":"2.   Quality check using FastQC","text":"<p>We now examine the quality of the bases. This will help us determine if there are parts of the reads that need to be trimmed/truncated. </p> <p>For the two fastq files you selected earlier, run fastqc as follows: Access the folder with all the raw .fastq (navigate with the <code>cd</code> command) files through Terminal (Mac Users) or Powershell (Windows Users). Next run the following command: </p> MacWindows <pre><code>fastqc *.fastq\n</code></pre> <p><pre><code>docker run --rm -v ${PWD}:/data/ -w /data/ -it pegi3s/fastqc IL10-1_S13_L001_R1_001.fastq\n</code></pre> Run this command independently for each unzipped file (in your Raw_data_unzipped folder). </p> Question(s): <ol> <li>Overall, which fastq file has higher quality scores, the R1 or R2?</li> <li>In each of these files, at which position do you observe a steep decline in base quality?</li> </ol>"},{"location":"workflow/#3-qiime2","title":"3.  QIIME2","text":"<p>We will now use QIIME2 for the next steps in the workflow: these involve importing the fastq files, trimming the primers, \"cleaning up\" the reads the merging the forward and reverse reads, generating a table containing information on the reads and their abundance, assigning taxonomy to these reads, and carrying out statistical analyses on bacterial diversity. </p>"},{"location":"workflow/#31-activate-qiime-2-environment","title":"3.1 Activate QIIME 2 environment","text":"<p>Set the path to the correct directory after downloading the necessary folder from Switchdrive (https://drive.switch.ch/index.php/s/i97MUDfcbcFNQVp)</p> <p>As a first step, activate QIIME with the following command (before doing so, navigate into the folder where you downloaded and unzipped the file from Switchdrive \"Practical_materials_uploads\"):</p> MacWindows <pre><code>conda activate qiime2-amplicon-2025.7\n</code></pre> <pre><code>docker run --rm -v ${PWD}:/data/ -w /data/ -it quay.io/qiime2/amplicon:2025.7 \n</code></pre>"},{"location":"workflow/#32-import-raw-data","title":"3.2. Import raw data","text":"<p>Before you start: Open your terminal and navigate into the folder where the raw data is stored (<code>Practical_material_uploads</code>) using the <code>cd</code> (change directory) command:</p> <p><pre><code>cd /path/to/Practical_material_uploads\n</code></pre> This ensures you are in the correct working directory before running the <code>qiime tools import</code> command.</p> <p>Next, you will import the raw data (fastq files) by running qiime tools import. Notice that with this tool, each of the parameters you can provide starts with two dashes. Here you will be specifying the following parameters:</p> <ul> <li>type: whether your data is single-end or paired-end</li> <li>input-format specifies the format of the data. The available choices are provided here</li> <li>output-path: species the output path of the artefact you generate.</li> </ul> <p>Run the following command:</p> <pre><code>qiime tools import \\\n    --type 'SampleData[PairedEndSequencesWithQuality]' \\\n    --input-path Raw_data_zipped \\\n    --input-format CasavaOneEightSingleLanePerSampleDirFmt \\\n    --output-path QIIME2_files/demux-paired-end.qza\n</code></pre>"},{"location":"workflow/#321-summarise-imported-data-and-visualise","title":"3.2.1 Summarise imported data and visualise","text":"<p>You can now check whether the data was imported by running qiime demux summarise, specifying the name of the input file and the name of the artefact you want to generate. You can visualise this artefact by dropping it in QIIME2 view (https://view.qiime2.org/). </p> <pre><code>qiime demux summarize \\\n    --i-data QIIME2_files/demux-paired-end.qza \\\n    --o-visualization QIIME2_files/demux-paired-end-summary.qzv  \n</code></pre> Question(s): Basic - Check the \u201cOverview\u201d tabAdvanced \u2013 check the \u201cInteractive\u201d tab <ol> <li>How many forward and reverse reads are there overall?</li> <li>For the samples you examined on FastQC, how many forward reads and reverse reads are there?</li> <li>Do any samples stand out eg have a particularly high or low number of reads? </li> </ol> <ol> <li>Look at the plots and the quality scores: What trends do you observe in terms of quality score changes in the forward and reverse reads?</li> <li>Scroll down to the \u201cDemultiplexed sequence length summary\u201d: What is the read length? How much overlap do you expect for the forward and reverse reads? </li> </ol>"},{"location":"workflow/#33-remove-primers-with-cutadapt","title":"3.3 Remove primers with Cutadapt","text":"<p>We need to remove the primers that were used for targeted amplification. To do this we use cutadapt trim-paired, specifying these main parameters:</p> <ul> <li>forward primer: which is \u201cGTGYCAGCMGCCGCGGTAA\u201d</li> <li>reverse primer: which is \u201cCCGYCAATTYMTTTRAGTTT\u201d</li> <li>whether you have wobble bases</li> <li>whether you should discard reads that were not trimmed</li> </ul> tip: <p>--verbose: The verbose option specifies that you want to display detailed processing information on your screen. </p> <pre><code>qiime cutadapt trim-paired \\\n    --i-demultiplexed-sequences QIIME2_files/demux-paired-end.qza \\\n    --p-front-f GTGYCAGCMGCCGCGGTAA \\\n    --p-front-r CCGYCAATTYMTTTRAGTTT \\\n    --p-match-adapter-wildcards \\\n    --p-discard-untrimmed \\\n    --verbose \\\n    --o-trimmed-sequences QIIME2_files/paired-end-demux-trimmed.qza | tee QIIME2_files/cutadaptresults.log\n</code></pre> <p>Summarise the .qza artefact using the command below, and then visualise the trimmed reads in QIIME 2 view (https://view.qiime2.org/). </p> <pre><code>qiime demux summarize \\\n    --i-data QIIME2_files/paired-end-demux-trimmed.qza \\\n    --o-visualization QIIME2_files/paired-end-demux-trimmed-summary.qzv \n</code></pre> Question(s): Basic - Check the \u201cOverview\u201d tabAdvanced \u2013 check the \u201cInteractive\u201d tab <ol> <li>What are wobble bases? What does --p-match-adapter-wildcards do?  Tip: go to the Cutadapt website to find out (https://cutadapt.readthedocs.io/en/stable/)</li> <li>What does --p-discard-untrimmed do? What kinds of reads might not get trimmed? </li> <li>For the same samples explored earlier, how many reads are there?</li> </ol> <ol> <li>What are the read lengths now? What was the length of the primer sequences? </li> </ol>"},{"location":"workflow/#34-denoise-with-dada2","title":"3.4 Denoise with DADA2","text":"<p>Now we will \u201cdenoise\u201d the reads, that is, carry out a series of steps with the goal of retaining \u201ctrue\u201d reads, those that represent the taxa that are present in the sample. These reads may differ by one nucleotide, and they are referred to as exact sequence variants (ESVs) or amplicon sequence variants (ASVs). </p> <p>As we are working with paired end reads, we use qiime2 dada2 denoise-paired. Through this command, quality filtering, merging of forward and reverse reads, dereplication and removal of chimeras is conducted. </p> <p>The quality filtering aspect refers to trimming the ends of reads where quality is suboptimal, users can also discard sequences below a particular length. This step is done first to optimize the merging of forward and reverse reads. The merging is done according to default parameters (not specified in the command). </p> <p>Dereplication refers to checking the presence of all identical sequencing reads and then reducing these to one \u201cunique sequence\u201d with a note of its abundance.  Removal of chimeras refers to the removal of sequences that are \u201chybrids\u201d of different parent sequences, and which do not correspond to true ASVs.</p> <p>Here we will be specifying the following parameters: </p> <ul> <li>Truncation length for forward reads: at what length the forward reads will be cut and all reads below this length will be discarded</li> <li>Truncation length for reverse reads: at what length the reverse reads will be cut and all reads below this length will be discarded</li> </ul> <p>Note that now we will have 3 output files:</p> <ul> <li>an abundance table comprising the unique sequences and their abundance</li> <li>a fasta file with the unique sequences, which we refer to as the representative sequences</li> <li>a file containing the statistics for the denoising steps</li> </ul> <p>You can find more information on DADA2 here (https://benjjneb.github.io/dada2/).</p> <p>Run the following command: </p> <pre><code>qiime dada2 denoise-paired \\\n    --i-demultiplexed-seqs QIIME2_files/paired-end-demux-trimmed.qza \\\n    --p-trunc-len-f 225 \\\n    --p-trunc-len-r 225 \\\n    --o-table QIIME2_files/table.qza \\\n    --o-representative-sequences QIIME2_files/rep-seqs.qza \\\n    --o-denoising-stats QIIME2_files/denoising-stats.qza \n</code></pre>"},{"location":"workflow/#341-summarize-read-counts","title":"3.4.1 Summarize read counts","text":"<p>We will now summarise the number of reads that we have in each sample, having done the denoising. We use  feature-table summarize, providing a metadata file that contains information about our samples. </p> <p>Run the following command:  <pre><code>qiime feature-table summarize \\\n    --i-table QIIME2_files/table.qza \\\n    --o-visualization QIIME2_files/table.qzv \\\n    --m-sample-metadata-file Metadata/metadata.tsv\n</code></pre></p> <p>Open QIIME2 view (https://view.qiime2.org/) and drop the table.qzv in the drag&amp;drop window to see the results. </p> Question(s): <ol> <li>In the overview tab, what does number of features refer to?</li> <li>In the interactive tab, quantitatively compare the number of reads before and after denoising for all 18 samples.</li> <li>Get together in pairs, and calculate the percentage of reads that have been retained for each sample. </li> </ol> <p>Optional command: Visualise the representative sequences after denoising with DADA2 We use qiime feature-table tabulate-seqs to see the unique/representative sequences.</p> <p>Run the following command: </p> <pre><code>qiime feature-table tabulate-seqs \\\n    --i-data QIIME2_files/rep-seqs.qza \\\n    --o-visualization QIIME2_files/rep-seqs.qzv\n</code></pre> Question(s): <ol> <li>After running denoising with DADA2, we have obtained a set of amplicon sequence variants or exact sequence variants. Why is the length of these sequences different to that of the reads in the first fastq files you looked at?  </li> </ol>"},{"location":"workflow/#35-assign-taxonomy","title":"3.5  Assign taxonomy","text":"<p>We now assign taxonomy to the unique/representative sequences found across all samples. We do this with the q2-feature-classifier plugin, making use of a pre-trained Naive Bayes classifier. This classifier is an algorithm that was trained on the SILVA reference database (downloadedDecember 2019) comprising hundreds of thousands of bacterial sequences with taxonomic information. The output is a file containing the results for the different taxonomic ranks (from domain to species), and the level of confidence for the taxonomic assignment. </p> <pre><code>qiime feature-classifier classify-sklearn \\\n    --i-classifier Taxonomy_classifier/silva-138.1-V4V5-classifier_skl1.4.2.qza \\\n    --i-reads QIIME2_files/rep-seqs.qza \\\n    --o-classification QIIME2_files/taxonomy.qza\n</code></pre>"},{"location":"workflow/#351-tabulate-the-taxonomy-with-the-following-command","title":"3.5.1 Tabulate the taxonomy with the following command:","text":"<pre><code>qiime metadata tabulate \\\n    --m-input-file QIIME2_files/taxonomy.qza \\\n    --o-visualization QIIME2_files/taxonomy.qzv\n</code></pre> Question(s): BasicAdvanced <ol> <li>What are the different taxonomic ranks that are being assigned?</li> <li>Are there any sequences that are not bacterial? If so, what are they?</li> </ol> <ol> <li>Choose one of the features (ASVs), can you find its nucleotide sequence in another file? Once you have done so, check the taxonomic output obtained using blast, which implements a different algorithm. You can do so here:. Is the taxonomic assingment the same or different?</li> </ol> <p>\u26a0\ufe0f NOTE</p> <p> From this point onwards, the remaining commands in QIIME2 are OPTIONAL. We will now continue the analysis in RStudio. Please refer to the file: r_studio.md.  </p>"},{"location":"workflow/#36-filter-non-bacterial-sequences","title":"3.6 Filter non-bacterial sequences","text":"<p>Our library preparation and sequencing targets the prokaryotic 16S rRNA gene, but we may end up obtaining reads that are not prokaryotic eg from chloroplasts or mitochondria, and with reads that originate from archaea, which we are not looking at in this study. By using taxa filter-table we can specify what taxa we want to retain and what taxa we want to exclude in the ASV abundance table. With \u201cmode\u201d we are specifying that we want the search terms not to be case sensitive e.g. Eukaryota/eukaryota.</p> <p>Run the following commands:</p> <pre><code>qiime taxa filter-table \\\n--i-table QIIME2_files/table.qza \\\n--i-taxonomy QIIME2_files/taxonomy.qza \\\n--p-mode contains \\\n--p-include d__ \\\n--p-exclude 'd__;,Eukaryota' \\\n--o-filtered-table QIIME2_files/filtered-table.qza\n</code></pre> <pre><code>qiime feature-table filter-seqs \\\n--i-data QIIME2_files/rep-seqs.qza \\\n--i-table QIIME2_files/filtered-table.qza \\\n--o-filtered-data QIIME2_files/filtered-sequences.qza\n</code></pre> <pre><code>qiime feature-table summarize \\\n--i-table QIIME2_files/filtered-table.qza \\\n--o-visualization QIIME2_files/filtered-table.qzv \\\n--m-sample-metadata-file Metadata/metadata.tsv\n</code></pre> Question(s) <ol> <li>What are the last commands being used for?</li> </ol>"},{"location":"workflow/#37-generate-taxonomic-barplots","title":"3.7 Generate taxonomic barplots","text":"<p>In order to visualise the relative abundance of the taxa in each sample, we use taxa barplot</p> <p>Run the following command:</p> <pre><code>qiime taxa barplot \\\n--i-table QIIME2_files/filtered-table.qza \\\n--i-taxonomy QIIME2_files/taxonomy.qza \\\n--m-metadata-file Metadata/metadata.tsv \\\n--o-visualization QIIME2_files/taxa-bar-plots-1.qzv\n</code></pre> Question(s) <ol> <li>What taxonomic ranks correspond to the different \u201clevels\u201d?</li> <li>What patterns do you observe at the different taxonomic ranks/levels? Do you observe any differences across the three groups? </li> <li>Which taxonomic rank provides most information about the differences across the groups?</li> <li>Which taxa differ most, in terms of relative abundance, across the three groups?</li> <li>Investigate these taxa using online resources: what other relevant information can you find in the literature? </li> </ol>"},{"location":"workflow/#38-generate-the-rarefaction-curve","title":"3.8. Generate the rarefaction curve","text":"<p>We expect greater sequencing depth to allow us to capture bacterial diversity more accurately: as sequencing depth increases, more and more taxa are recovered. You can see this in the rarefaction plot, where we look at the changes in observed features (ASVs) recovered at different sequencing depths (number of reads sequenced). However, at a certain point we observe that the number of features recovered stabilises: we reach a plateau, and we infer that the sequencing depth is sufficient.</p> <p>Plot the rarefaction curves for the samples from the dataset using diversity alpha-rarefaction. </p> tip <p>Help on aplha diversity: qiime diversity alpha-rarefaction \u2013help</p> <pre><code>qiime diversity alpha-rarefaction \\\n    --i-table QIIME2_files/filtered-table.qza \\\n    --i-phylogeny Phylogenetic_tree/rooted-tree.qza \\\n    --m-metadata-file Metadata/metadata.tsv \\\n    --p-max-depth 88500 \\\n    --o-visualization QIIME2_files/alpha-rarefaction-plot.qzv\n</code></pre> Question(s): <ol> <li>Why did we specify a max depth of 88,500?</li> <li>Do you observe differences across the three groups?</li> </ol>"},{"location":"workflow/#39-core-metrics-phylogenetic-alpha-and-beta-diversities","title":"3.9. Core metrics phylogenetic: alpha and beta diversities\u00b6","text":"<p>To investigate alpha and beta diversity, we use diversity core-metrics-phylogenetic, computing the following metrics.</p> <ul> <li>Alpha diversity indices<ul> <li>Shannon\u2019s diversity </li> <li>Observed Features (in this case ASVs)</li> <li>Faith\u2019s Phylogenetic Diversity </li> <li>Evenness </li> </ul> </li> <li>Beta diversity distances<ul> <li>Jaccard distance </li> <li>Bray-Curtis distance </li> <li>unweighted UniFrac distance </li> <li>weighted UniFrac distance </li> </ul> </li> </ul> <p>To run these analyses, in addition to the ASV abundance table, we need to provide a phylogenetic tree (already generated for you) and the metadata file. To increase computational speed we use  the --p-n-jobs-or-threads.</p> <p>Importantly, diversity core-metrics-phylogenetic requires us to use the same sampling depth for all samples. Thus, we need to provide a sampling depth, that is, the number of total reads from each sample that will be used. If we want to keep all samples in the analyses, we will have to specify the minimum read depth in our sample set. Do you recall what this was? Make sure to specify it with--p-sampling-depth </p> <p>Run the following command:</p> <p>We use qiime diversity core-metrics-phylogenetic to generate a set of results. </p> <p><pre><code>qiime diversity core-metrics-phylogenetic \\\n    --i-phylogeny Phylogenetic_tree/rooted-tree.qza \\\n    --i-table QIIME2_files/filtered-table.qza \\\n    --p-sampling-depth xxxx \\\n    --p-n-jobs-or-threads 4 \\\n    --m-metadata-file Metadata/metadata.tsv \\\n    --output-dir QIIME2_files/diversity-core-metrics-phylogenetic\n</code></pre> View the folders that have been generated by running: </p> <pre><code>ls -l QIIME2_files/diversity-core-metrics-phylogenetic\n</code></pre>"},{"location":"workflow/#391-alpha-diversity-and-significance","title":"3.9.1 Alpha diversity and significance","text":"<p>We will first focus on alpha (intra-sample diversity) and return to beta diversities later again.  For the alpha diversity indices, we check whether there are significant differences across groups. We do so using diversity alpha-group significance. You can do this for any of the indices computed. </p> <p>Run the following command to test statistically significant differences for the \u201cobserved features\u201d index:</p> <pre><code>qiime diversity alpha-group-significance \\\n    --i-alpha-diversity QIIME2_files/diversity-core-metrics-phylogenetic/observed_features_vector.qza \\\n    --m-metadata-file Metadata/metadata.tsv \\\n    --o-visualization QIIME2_files/alpha-group-sig-obs-feats.qzv\n</code></pre> Question(s): <ol> <li>Explore the alpha diversity indices, and test statistical significance for these. In pairs, discuss the patterns observed. Which \u201cgroups\u201d of samples have higher intra-sample diversity? Which groups have lower intra-sample diversity? What could be potential explanations?  </li> <li>Are the alpha diversity patterns congruent with the taxonomic composition observed in the barplots?</li> </ol> <p>For turbo learners Now run the previous command specifying different sampling depths (remember to save the output file under a different name). </p>"},{"location":"workflow/#392-beta-diversity-and-significance","title":"3.9.2 Beta diversity and significance","text":"<p>We now focus on beta diversity (inter-sample diversity). To test significance we use diversity beta-group significance. We will do so for the Bray Curtis distance matrix. </p> <pre><code>qiime diversity beta-group-significance \\\n    --i-distance-matrix QIIME2_files/diversity-core-metrics-phylogenetic/bray_curtis_distance_matrix.qza \\\n    --m-metadata-file Metadata/metadata.tsv \\\n    --m-metadata-column type \\\n    --o-visualization QIIME2_files/diversity-core-metrics-phylogenetic/braycurtis-type-significance.qzv \\\n    --p-pairwise\n</code></pre> Question(s): <ol> <li>Explore the different distance metrics and the corresponding PCoA plots generated. What are the similarities and differences?  </li> <li>Now focus on the weighted and the unweighted unifrac distance matrices. Are there significant differences across the groups with these distance matrices?</li> </ol>"}]}